{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Art Generation using GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-manic/Art-generation-using-GANS/blob/main/Art_Generation_using_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91etOQrx9OeT"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTwfWwk09z38",
        "outputId": "38a44d13-7a49-4e07-a8e0-0ea0608ee14e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8mMXURK8moz"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9R5VqVL9iQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd45e97-6852-4e17-b93e-592c7c9a6efb"
      },
      "source": [
        "batch_size = 128\n",
        "image_size = (64,64) #all images are resized to this size \n",
        "device = get_default_device()\n",
        "latent_size = 150 #can be changed\n",
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)\n",
        "lr = 0.0015\n",
        "epochs = 300\n",
        "\n",
        "\n",
        "input_dir = \"/content/gdrive/MyDrive/ECE 283 Project/1/\"\n",
        "output_dir = \"/content/gdrive/MyDrive/ECE 283 Project/1_lr0.0015_generated/\"\n",
        "os.makedirs(output_dir, exist_ok = True)\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy--_S219oDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81be9b27-22f7-4dcd-aec4-5a75ecedd40f"
      },
      "source": [
        "transform_dataset = transforms.Compose([transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=input_dir, transform=transform_dataset)\n",
        "\n",
        "train_data = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
        "\n",
        "train_data = DeviceDataLoader(train_data, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Vx3IseBl5X"
      },
      "source": [
        "def denormalize(img_tensors):\n",
        "    #denormalizes the image noramlized in the transforms\n",
        "    return img_tensors * 0.5 + 0.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvqTWCaAhcX"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 31 x 31\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 14 x 14\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 6 x 6\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 2 x 2\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=2, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    # out : 1\n",
        "    nn.Sigmoid()\n",
        "    # out : 1\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DQG5_XxA1vo"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0BkDrGZA4je"
      },
      "source": [
        "discriminator = to_device(discriminator, device)\n",
        "generator = to_device(generator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCMO-xm7A6ZP"
      },
      "source": [
        "def train_discriminator(real_images, optimizer_dis):\n",
        "    # Clear discriminator gradients\n",
        "    optimizer_dis.zero_grad()\n",
        "\n",
        "    # Pass real images through discriminator\n",
        "    real_predicted_labels = discriminator(real_images)\n",
        "    real_true_lables = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_data_loss = F.binary_cross_entropy(real_predicted_labels, real_true_lables)\n",
        "    real_accuracy = torch.mean(real_predicted_labels).item()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    generated_images = generator(latent)\n",
        "\n",
        "    # Pass generated images through discriminator\n",
        "    fake_predicted_labels = discriminator(generated_images)\n",
        "    fake_true_labels = torch.zeros(generated_images.size(0), 1, device=device)\n",
        "    fake_data_loss = F.binary_cross_entropy(fake_predicted_labels, fake_true_labels)\n",
        "    fake_accuracy = torch.mean(fake_predicted_labels).item()\n",
        "\n",
        "    # Update discriminator weights and compute total discriminator loss\n",
        "    discriminator_loss = real_data_loss + fake_data_loss\n",
        "    discriminator_loss.backward()\n",
        "    optimizer_dis.step()\n",
        "    return discriminator_loss.item(), real_accuracy, fake_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYr-pZ2wA7r3"
      },
      "source": [
        "def train_generator(optimizer_gen):\n",
        "    # Clear generator gradients\n",
        "    optimizer_gen.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Pass generated images through discriminator\n",
        "    fake_predicted_labels = discriminator(fake_images)\n",
        "    fake_true_labels = torch.ones(batch_size, 1, device=device)\n",
        "    generator_loss = F.binary_cross_entropy(fake_predicted_labels, fake_true_labels)\n",
        "    \n",
        "    # Update generator weights and compute generator loss\n",
        "    generator_loss.backward()\n",
        "    optimizer_gen.step()\n",
        "    \n",
        "    return generator_loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR3H0SD0A9pO"
      },
      "source": [
        "def save_samples(index, latent_tensors):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    img_name = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denormalize(fake_images), os.path.join(output_dir, img_name), nrow=8)\n",
        "    print('Saving', img_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl4K-DmJBXWS"
      },
      "source": [
        "def fit(epochs, lr, start_index=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    loss_discriminator = []\n",
        "    loss_generator = []\n",
        "    real_accuracy_prob = []\n",
        "    fake_accuracy_prob = []\n",
        "    \n",
        "    # Create optimizers\n",
        "    optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_data):\n",
        "            # Train discriminator\n",
        "            discriminator_loss, real_accuracy, fake_accuracy = train_discriminator(real_images, optimizer_dis)\n",
        "            # Train generator\n",
        "            generator_loss = train_generator(optimizer_gen)\n",
        "            \n",
        "        # Record losses & scores\n",
        "        loss_discriminator.append(discriminator_loss)\n",
        "        loss_generator.append(generator_loss)\n",
        "        real_accuracy_prob.append(real_accuracy)\n",
        "        fake_accuracy_prob.append(fake_score)\n",
        "        \n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], discriminator_loss: {:.4f}, generator_loss: {:.4f}, real_accuracy: {:.4f}, fake_accuracy: {:.4f}\".format(\n",
        "            epoch+1, epochs, discriminator_loss, generator_loss, real_accuracy, fake_accuracy))\n",
        "    \n",
        "        # save_samples(epoch+start_index, fixed_latent)\n",
        "    \n",
        "    return loss_discriminator, loss_generator, real_accuracy_prob, fake_accuracy_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN4OACoSBaEM"
      },
      "source": [
        "history = fit(epochs,lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U38UOs4BmX-"
      },
      "source": [
        "loss_discriminator, loss_generator, real_accuracy_prob, fake_accuracy_prob = history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2v0B5I0BoPx"
      },
      "source": [
        "torch.save(generator.state_dict(), 'Generator.ckpt')\n",
        "torch.save(discriminator.state_dict(), 'Discriminator.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIr4bLQsBpsC"
      },
      "source": [
        "plt.plot(loss_discriminator, '-')\n",
        "plt.plot(loss_generator, '-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Cross-Entropy Losses of Discriminator and Generator');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cM4nbJ2Bq8F"
      },
      "source": [
        "plt.plot(real_accuracy_prob, '-')\n",
        "plt.plot(fake_accuracy_prob, '-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Accuracy of the model');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Zui0YEBsS0"
      },
      "source": [
        "vid_fname = '{}/gans_training.avi'.format(output_dir)\n",
        "\n",
        "files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if 'generated' in f]\n",
        "files.sort()\n",
        "\n",
        "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}